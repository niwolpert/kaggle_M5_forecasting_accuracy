{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/m5-preloaded-data/sales_train_val.csv\n/kaggle/input/m5-forecasting-accuracy/calendar.csv\n/kaggle/input/m5-forecasting-accuracy/sell_prices.csv\n/kaggle/input/m5-forecasting-accuracy/sales_train_validation.csv\n/kaggle/input/m5-forecasting-accuracy/sample_submission.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import libraries\nimport gc\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport seaborn as sns\n\nimport time\nimport math\n\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.ensemble import RandomForestRegressor\nimport lightgbm as lgb\n\nfrom sklearn import preprocessing, metrics\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import subprocess\nimport sys\n# for uninstalled packages, use:\ndef install(package):\n    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Memory optimization\n\n# Original code from https://www.kaggle.com/gemartin/load-data-reduce-memory-usage by @gemartin\n# Modified by @Vopani\n\n# to support timestamp type, categorical type and to add option to use float16\nfrom pandas.api.types import is_datetime64_any_dtype as is_datetime\nfrom pandas.api.types import is_categorical_dtype\n\ndef reduce_mem_usage(df, use_float16=False):\n    \"\"\"\n    Iterate through all the columns of a dataframe and modify the data type to reduce memory usage.        \n    \"\"\"\n    \n    start_mem = df.memory_usage().sum() / 1024**2\n    print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n    \n    for col in df.columns:\n        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n            continue\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == \"int\":\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype(\"category\")\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n    print(\"Decreased by {:.1f}%\".format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# specify path to raw data\npath_data = '/kaggle/input/m5-forecasting-accuracy/'","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_columns', 500)\npd.set_option('display.max_rows', 500)","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## First data inspection"},{"metadata":{"trusted":true},"cell_type":"code","source":"sell_prices = pd.read_csv(path_data + 'sell_prices.csv')\ncalendar = pd.read_csv(path_data + 'calendar.csv')\nsales_train_val = pd.read_csv(path_data + 'sales_train_validation.csv')\nsubmission = pd.read_csv(path_data + 'sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sell_prices.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sell_prices.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calendar.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calendar.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calendar.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calendar.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"calendar[['event_name_1','event_type_1','event_name_2','event_type_2']].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train_val.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train_val.cat_id.unique().tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sales_train_val.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# count number of zero and nonzero elements for each feature\nnonzero_total = sales_train_val.drop(columns=['id','item_id','dept_id','cat_id','store_id','state_id'], axis=1).astype(bool).sum(axis=0).sort_values(ascending = False)\nnonzero_perc = nonzero_total/sales_train_val.shape[0]\nnonzero = pd.concat([nonzero_total, nonzero_perc], axis=1, keys=['Total', 'Percent'])\n\n# display featues with most and fewest nonzero elements\nprint('Nonzero elements by feature: ')\nnonzero.head(10).append(nonzero.tail(10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del sell_prices, calendar, sales_train_val, submission, nonzero\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Transform data"},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_and_transform(start_day):\n\n    dtypes_calendar={\"event_name_1\": \"category\", \"event_name_2\": \"category\", \"event_type_1\": \"category\", \n             \"event_type_2\": \"category\", \"weekday\": \"category\", 'wm_yr_wk': 'int16', \"wday\": \"int16\",\n            \"month\": \"int16\", \"year\": \"int16\", \"snap_CA\": \"float32\", 'snap_TX': 'float32', 'snap_WI': 'float32' }\n    dtypes_sell_prices = {\"store_id\": \"category\", \"item_id\": \"category\", \"wm_yr_wk\": \"int16\",\"sell_price\":\"float32\" }\n\n    # transform categorical variables into int16 format since it saves memory\n\n    sell_prices = pd.read_csv(path_data + 'sell_prices.csv', dtype = dtypes_sell_prices)\n\n    for col, col_dtype in dtypes_sell_prices.items():\n        if col_dtype == \"category\":\n            sell_prices[col] = sell_prices[col].cat.codes.astype(\"int16\")\n            sell_prices[col] -= sell_prices[col].min()\n\n    calendar = pd.read_csv(path_data + 'calendar.csv', dtype = dtypes_calendar)\n\n    calendar[\"date\"] = pd.to_datetime(calendar[\"date\"])\n    for col, col_dtype in dtypes_calendar.items():\n        if col_dtype == \"category\":\n            calendar[col] = calendar[col].cat.codes.astype(\"int16\")\n            calendar[col] -= calendar[col].min()\n\n    # start from given day\n\n    numcols = [f\"d_{day}\" for day in range(start_day,1914)]\n    catcols = ['id', 'item_id', 'dept_id','store_id', 'cat_id', 'state_id']\n    dtype = {numcol:\"float32\" for numcol in numcols} \n    dtype.update({col: \"category\" for col in catcols if col != \"id\"})\n    sales_train_val = pd.read_csv(path_data + 'sales_train_validation.csv', usecols = catcols + numcols, dtype = dtype)\n\n    # transform categorical columsn to integer to save memory\n    for col in catcols:\n        if col != \"id\":\n            sales_train_val[col] = sales_train_val[col].cat.codes.astype(\"int16\")\n            sales_train_val[col] -= sales_train_val[col].min()\n\n    print('###### Transforming into melted and merged data format...')\n\n    ### melt sales dataframe\n\n    id_columns = ['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']\n    sales_melt = sales_train_val.melt(\n        id_vars=id_columns, value_vars = sales_train_val.drop(id_columns, axis=1).columns, \n        var_name='d', \n        value_name='sales'\n    )\n    sales_melt = reduce_mem_usage(sales_melt)\n\n    # get product table\n    product_infos = sales_train_val[id_columns].drop_duplicates()\n\n    del sales_train_val\n\n    ### melt submission dataframe\n\n    submission = pd.read_csv(path_data + 'sample_submission.csv')\n\n    sub_cols = submission.drop(['id'], axis=1).columns\n\n    submission_melt = submission.melt(\n        id_vars = ['id'],\n        value_vars = sub_cols, \n        var_name = 'd',\n        value_name = 'sales')\n\n    del submission\n\n    ### convert submission df to appropiate day format\n    submission_melt['d'] = submission_melt['d'].str.replace('F','')\n    submission_melt['d'] = pd.to_numeric(submission_melt['d'], errors='coerce')\n\n    submission_melt.loc[submission_melt[\"id\"].str.contains(\"validation\"), 'd'] += 1913\n    submission_melt.loc[submission_melt[\"id\"].str.contains(\"evaluation\"), 'd'] += 1941\n\n    submission_melt = submission_melt.applymap(str)\n    submission_melt['d'] = 'd_'+ submission_melt['d'].astype(str)\n\n    submission_melt.sales = submission_melt.sales.astype('float32')\n\n    submission_melt=reduce_mem_usage(submission_melt)\n\n    ### split up into training, validation and test data set\n    # - submission consisting of:\n    #   *sales from day 1914-1941 (used for the leaderbord)\n    #   *sales fro day 1942-1970 (used for final score)\n\n    # merge product infos on submission file\n\n    # temporarily separate test dataframes\n    df_submission1 = submission_melt[submission_melt[\"id\"].str.contains(\"validation\")]\n    df_submission2 = submission_melt[submission_melt[\"id\"].str.contains(\"evaluation\")]\n\n    del submission_melt\n\n    # merge with product table\n    # to do that we have to temporarily rename values in the id column\n    df_submission2[\"id\"] = df_submission2[\"id\"].str.replace(\"_evaluation\", \"_validation\")\n    df_submission1 = df_submission1.merge(product_infos, how=\"left\", on=\"id\")\n    df_submission2 = df_submission2.merge(product_infos, how=\"left\", on=\"id\")\n    df_submission2[\"id\"] = df_submission2[\"id\"].str.replace(\"_validation\", \"_evaluation\")\n    df_submission1['part'] = 'public_leaderboard'\n    df_submission2['part'] = 'private_leaderboard'\n\n    # for the moment only use public leaderboard data\n    #df_submission = pd.concat([df_submission1, df_submission2], axis=0)\n    df_submission = df_submission1.copy()\n\n    df_submission=reduce_mem_usage(df_submission)\n\n    del product_infos, df_submission1, df_submission2\n    gc.collect()\n\n    ### Merge calendar data\n    # drop time features (own ones will be added)\n    calendar = calendar.drop([\"weekday\", \"wday\", \"month\", \"year\"], axis=1)\n    df_train_val = sales_melt.merge(calendar, how=\"left\", on=\"d\")\n    del sales_melt\n    df_submission = df_submission.merge(calendar, how=\"left\", on=\"d\")\n\n    del calendar\n\n    # Merge sell price data\n    # CHANGE BACK TO LEFT JOIN\n    #df_train_val = df_train_val.merge(sell_prices, on=[\"store_id\", \"item_id\", \"wm_yr_wk\"], how=\"left\")\n    #df_submission = df_submission.merge(sell_prices, on=[\"store_id\", \"item_id\", \"wm_yr_wk\"], how=\"left\")\n    df_train_val = df_train_val.merge(sell_prices, on=[\"store_id\", \"item_id\", \"wm_yr_wk\"])\n    df_submission = df_submission.merge(sell_prices, on=[\"store_id\", \"item_id\", \"wm_yr_wk\"])\n\n    del sell_prices\n\n    df_train_val['part'] = 'train_val'\n    df_submission = df_submission[df_train_val.columns]\n\n    ### Merge trains and submission dfs\n    df_train_val_test = pd.concat([df_train_val, df_submission], axis=0)\n\n    del df_train_val, df_submission\n\n    ### add time-features\n    df_train_val_test['date'] = pd.to_datetime(df_train_val_test.date, format=\"%Y-%m-%d %H:%M:%S\")\n    df_train_val_test['year'] = df_train_val_test.date.dt.year\n    df_train_val_test['month'] = df_train_val_test.date.dt.month\n    df_train_val_test['day'] = df_train_val_test.date.dt.day\n    df_train_val_test['weekday'] = df_train_val_test.date.dt.weekday\n    df_train_val_test['hour'] = df_train_val_test.date.dt.hour\n\n    df_train_val_test = reduce_mem_usage(df_train_val_test)\n\n    gc.collect()\n    \n    return df_train_val_test\n\nstart_day = 800\ndf_train_val_test = read_and_transform(start_day)","execution_count":7,"outputs":[{"output_type":"stream","text":"###### Transforming into melted and merged data format...\nMemory usage of dataframe is 971.77 MB\nMemory usage after optimization is: 455.02 MB\nDecreased by 53.2%\nMemory usage of dataframe is 32.57 MB\nMemory usage after optimization is: 17.62 MB\nDecreased by 45.9%\nMemory usage of dataframe is 31.76 MB\nMemory usage after optimization is: 19.40 MB\nDecreased by 38.9%\nMemory usage of dataframe is 3397.87 MB\nMemory usage after optimization is: 1823.23 MB\nDecreased by 46.3%\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_val_test.head()","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"                              id  item_id  dept_id  cat_id  store_id  \\\n0  HOBBIES_1_002_CA_1_validation        1        0       0         0   \n1  HOBBIES_1_002_CA_1_validation        1        0       0         0   \n2  HOBBIES_1_002_CA_1_validation        1        0       0         0   \n3  HOBBIES_1_002_CA_1_validation        1        0       0         0   \n4  HOBBIES_1_002_CA_1_validation        1        0       0         0   \n\n   state_id      d  sales       date  wm_yr_wk  event_name_1  event_type_1  \\\n0         0  d_800    0.0 2013-04-07     11311             0             0   \n1         0  d_801    0.0 2013-04-08     11311             0             0   \n2         0  d_802    0.0 2013-04-09     11311             0             0   \n3         0  d_803    0.0 2013-04-10     11311             0             0   \n4         0  d_804    0.0 2013-04-11     11311             0             0   \n\n   event_name_2  event_type_2  snap_CA  snap_TX  snap_WI  sell_price  \\\n0             0             0      1.0      1.0      0.0        3.97   \n1             0             0      1.0      0.0      1.0        3.97   \n2             0             0      1.0      1.0      1.0        3.97   \n3             0             0      1.0      0.0      0.0        3.97   \n4             0             0      0.0      1.0      1.0        3.97   \n\n        part  year  month  day  weekday  hour  \n0  train_val  2013      4    7        6     0  \n1  train_val  2013      4    8        0     0  \n2  train_val  2013      4    9        1     0  \n3  train_val  2013      4   10        2     0  \n4  train_val  2013      4   11        3     0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>item_id</th>\n      <th>dept_id</th>\n      <th>cat_id</th>\n      <th>store_id</th>\n      <th>state_id</th>\n      <th>d</th>\n      <th>sales</th>\n      <th>date</th>\n      <th>wm_yr_wk</th>\n      <th>event_name_1</th>\n      <th>event_type_1</th>\n      <th>event_name_2</th>\n      <th>event_type_2</th>\n      <th>snap_CA</th>\n      <th>snap_TX</th>\n      <th>snap_WI</th>\n      <th>sell_price</th>\n      <th>part</th>\n      <th>year</th>\n      <th>month</th>\n      <th>day</th>\n      <th>weekday</th>\n      <th>hour</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HOBBIES_1_002_CA_1_validation</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>d_800</td>\n      <td>0.0</td>\n      <td>2013-04-07</td>\n      <td>11311</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>3.97</td>\n      <td>train_val</td>\n      <td>2013</td>\n      <td>4</td>\n      <td>7</td>\n      <td>6</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HOBBIES_1_002_CA_1_validation</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>d_801</td>\n      <td>0.0</td>\n      <td>2013-04-08</td>\n      <td>11311</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3.97</td>\n      <td>train_val</td>\n      <td>2013</td>\n      <td>4</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HOBBIES_1_002_CA_1_validation</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>d_802</td>\n      <td>0.0</td>\n      <td>2013-04-09</td>\n      <td>11311</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.97</td>\n      <td>train_val</td>\n      <td>2013</td>\n      <td>4</td>\n      <td>9</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HOBBIES_1_002_CA_1_validation</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>d_803</td>\n      <td>0.0</td>\n      <td>2013-04-10</td>\n      <td>11311</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.97</td>\n      <td>train_val</td>\n      <td>2013</td>\n      <td>4</td>\n      <td>10</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HOBBIES_1_002_CA_1_validation</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>d_804</td>\n      <td>0.0</td>\n      <td>2013-04-11</td>\n      <td>11311</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.97</td>\n      <td>train_val</td>\n      <td>2013</td>\n      <td>4</td>\n      <td>11</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_val_test.shape","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"(32376116, 24)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_val_test.info()","execution_count":10,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 32376116 entries, 0 to 853719\nData columns (total 24 columns):\nid              category\nitem_id         int16\ndept_id         int8\ncat_id          int8\nstore_id        int8\nstate_id        int8\nd               category\nsales           float32\ndate            datetime64[ns]\nwm_yr_wk        int16\nevent_name_1    int8\nevent_type_1    int8\nevent_name_2    int8\nevent_type_2    int8\nsnap_CA         float32\nsnap_TX         float32\nsnap_WI         float32\nsell_price      float32\npart            category\nyear            int16\nmonth           int8\nday             int8\nweekday         int8\nhour            int8\ndtypes: category(3), datetime64[ns](1), float32(5), int16(3), int8(12)\nmemory usage: 1.8 GB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check if dates are correct:\n# public leaderboard data should begin with d_1914 and 2016-04-25\ndf_train_val_test[df_train_val_test.part=='public_leaderboard'].head()","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"                              id  item_id  dept_id  cat_id  store_id  \\\n0  HOBBIES_1_001_CA_1_validation        0        0       0         0   \n1  HOBBIES_1_001_CA_1_validation        0        0       0         0   \n2  HOBBIES_1_001_CA_1_validation        0        0       0         0   \n3  HOBBIES_1_001_CA_1_validation        0        0       0         0   \n4  HOBBIES_1_001_CA_1_validation        0        0       0         0   \n\n   state_id       d  sales       date  wm_yr_wk  event_name_1  event_type_1  \\\n0         0  d_1914    0.0 2016-04-25     11613             0             0   \n1         0  d_1915    0.0 2016-04-26     11613             0             0   \n2         0  d_1916    0.0 2016-04-27     11613             0             0   \n3         0  d_1917    0.0 2016-04-28     11613             0             0   \n4         0  d_1918    0.0 2016-04-29     11613             0             0   \n\n   event_name_2  event_type_2  snap_CA  snap_TX  snap_WI  sell_price  \\\n0             0             0      0.0      0.0      0.0        8.38   \n1             0             0      0.0      0.0      0.0        8.38   \n2             0             0      0.0      0.0      0.0        8.38   \n3             0             0      0.0      0.0      0.0        8.38   \n4             0             0      0.0      0.0      0.0        8.38   \n\n                 part  year  month  day  weekday  hour  \n0  public_leaderboard  2016      4   25        0     0  \n1  public_leaderboard  2016      4   26        1     0  \n2  public_leaderboard  2016      4   27        2     0  \n3  public_leaderboard  2016      4   28        3     0  \n4  public_leaderboard  2016      4   29        4     0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>item_id</th>\n      <th>dept_id</th>\n      <th>cat_id</th>\n      <th>store_id</th>\n      <th>state_id</th>\n      <th>d</th>\n      <th>sales</th>\n      <th>date</th>\n      <th>wm_yr_wk</th>\n      <th>event_name_1</th>\n      <th>event_type_1</th>\n      <th>event_name_2</th>\n      <th>event_type_2</th>\n      <th>snap_CA</th>\n      <th>snap_TX</th>\n      <th>snap_WI</th>\n      <th>sell_price</th>\n      <th>part</th>\n      <th>year</th>\n      <th>month</th>\n      <th>day</th>\n      <th>weekday</th>\n      <th>hour</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HOBBIES_1_001_CA_1_validation</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>d_1914</td>\n      <td>0.0</td>\n      <td>2016-04-25</td>\n      <td>11613</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>8.38</td>\n      <td>public_leaderboard</td>\n      <td>2016</td>\n      <td>4</td>\n      <td>25</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HOBBIES_1_001_CA_1_validation</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>d_1915</td>\n      <td>0.0</td>\n      <td>2016-04-26</td>\n      <td>11613</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>8.38</td>\n      <td>public_leaderboard</td>\n      <td>2016</td>\n      <td>4</td>\n      <td>26</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HOBBIES_1_001_CA_1_validation</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>d_1916</td>\n      <td>0.0</td>\n      <td>2016-04-27</td>\n      <td>11613</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>8.38</td>\n      <td>public_leaderboard</td>\n      <td>2016</td>\n      <td>4</td>\n      <td>27</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HOBBIES_1_001_CA_1_validation</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>d_1917</td>\n      <td>0.0</td>\n      <td>2016-04-28</td>\n      <td>11613</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>8.38</td>\n      <td>public_leaderboard</td>\n      <td>2016</td>\n      <td>4</td>\n      <td>28</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HOBBIES_1_001_CA_1_validation</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>d_1918</td>\n      <td>0.0</td>\n      <td>2016-04-29</td>\n      <td>11613</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>8.38</td>\n      <td>public_leaderboard</td>\n      <td>2016</td>\n      <td>4</td>\n      <td>29</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"d_cols = [col for col in sales_train_val.columns if 'd_' in col]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_per_cat = sales_train_val.groupby('cat_id').agg('mean').T.reset_index().drop('index', axis=1)\nax = mean_per_cat.plot(figsize=(15, 7))\nax.set_xlabel(\"day\", fontsize=15)\nax.set_ylabel(\"avg sells\", fontsize=15)\nax.tick_params(labelsize=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prop_nonzero = sales_train_val[d_cols].astype(bool).sum(axis=0).reset_index().drop('index', axis=1)/sales_train_val.shape[0]\nax = prop_nonzero.plot(figsize=(15, 7))\nax.set_xlabel(\"day\", fontsize=15)\nax.set_ylabel(\"Proportion at least 1 sale\", fontsize=15)\nax.tick_params(labelsize=15)\nax.get_legend().remove()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1,3,figsize=(30,7))\n\ndf_train_val_test.groupby(['cat_id']).agg({'sales': 'mean'}).plot(kind='bar', rot=0, ax=axes[0])\naxes[0].xaxis.set_label_text('')\naxes[0].set_xticklabels(['Food','Hobbies','Household'], fontsize=15)\naxes[0].set_ylabel('Mean sell price', fontsize=20)\naxes[0].tick_params(labelsize=20)\naxes[0].get_legend().remove()\n\ndf_train_val_test.groupby(['dept_id']).agg({'sales': 'mean'}).plot(kind='bar', rot=45, ax=axes[1])\naxes[1].xaxis.set_label_text('')\naxes[1].set_xlabel('Department', fontsize=20)\naxes[1].set_ylabel('Mean sell price', fontsize=20)\naxes[1].tick_params(labelsize=17,rotation=0)\naxes[1].get_legend().remove()\n\ndf_train_val_test.groupby(['store_id']).agg({'sales': 'mean'}).plot(kind='bar', rot=45, ax=axes[2])\naxes[2].xaxis.set_label_text('')\naxes[2].set_xlabel('Store', fontsize=20)\naxes[2].set_ylabel('Mean sell price', fontsize=20)\naxes[2].tick_params(labelsize=20,rotation=0)\naxes[2].get_legend().remove()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# there are few changes in sell price\nprice_range_per_id = df_train_val_test.groupby('id')['sell_price'].agg(np.ptp)\nplt.figure(figsize=(7,3))\n_ = plt.hist(price_range_per_id, bins=100)\n_ =plt.xlabel('max-min sell price per id', fontsize=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"agg = df_train_val_test.groupby(['cat_id']).agg({'sales': 'mean'})\nagg","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Label-encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_val_test.head()","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"                              id  item_id  dept_id  cat_id  store_id  \\\n0  HOBBIES_1_002_CA_1_validation        1        0       0         0   \n1  HOBBIES_1_002_CA_1_validation        1        0       0         0   \n2  HOBBIES_1_002_CA_1_validation        1        0       0         0   \n3  HOBBIES_1_002_CA_1_validation        1        0       0         0   \n4  HOBBIES_1_002_CA_1_validation        1        0       0         0   \n\n   state_id      d  sales       date  wm_yr_wk  event_name_1  event_type_1  \\\n0         0  d_800    0.0 2013-04-07     11311             0             0   \n1         0  d_801    0.0 2013-04-08     11311             0             0   \n2         0  d_802    0.0 2013-04-09     11311             0             0   \n3         0  d_803    0.0 2013-04-10     11311             0             0   \n4         0  d_804    0.0 2013-04-11     11311             0             0   \n\n   event_name_2  event_type_2  snap_CA  snap_TX  snap_WI  sell_price  \\\n0             0             0      1.0      1.0      0.0        3.97   \n1             0             0      1.0      0.0      1.0        3.97   \n2             0             0      1.0      1.0      1.0        3.97   \n3             0             0      1.0      0.0      0.0        3.97   \n4             0             0      0.0      1.0      1.0        3.97   \n\n        part  year  month  day  weekday  hour  item_sales_per_day  \\\n0  train_val  2013      4    7        6     0                 5.0   \n1  train_val  2013      4    8        0     0                 1.0   \n2  train_val  2013      4    9        1     0                 2.0   \n3  train_val  2013      4   10        2     0                 2.0   \n4  train_val  2013      4   11        3     0                 3.0   \n\n   item_sales_per_store  item_sales_per_store_day  revenue  \\\n0                 319.0                       0.0      0.0   \n1                 319.0                       0.0      0.0   \n2                 319.0                       0.0      0.0   \n3                 319.0                       0.0      0.0   \n4                 319.0                       0.0      0.0   \n\n   total_revenue_per_store  total_revenue_per_day  \n0               15528686.0              4469083.5  \n1               15528686.0              4445660.0  \n2               15528686.0              4557555.0  \n3               15528686.0              4301710.5  \n4               15528686.0              4401590.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>item_id</th>\n      <th>dept_id</th>\n      <th>cat_id</th>\n      <th>store_id</th>\n      <th>state_id</th>\n      <th>d</th>\n      <th>sales</th>\n      <th>date</th>\n      <th>wm_yr_wk</th>\n      <th>event_name_1</th>\n      <th>event_type_1</th>\n      <th>event_name_2</th>\n      <th>event_type_2</th>\n      <th>snap_CA</th>\n      <th>snap_TX</th>\n      <th>snap_WI</th>\n      <th>sell_price</th>\n      <th>part</th>\n      <th>year</th>\n      <th>month</th>\n      <th>day</th>\n      <th>weekday</th>\n      <th>hour</th>\n      <th>item_sales_per_day</th>\n      <th>item_sales_per_store</th>\n      <th>item_sales_per_store_day</th>\n      <th>revenue</th>\n      <th>total_revenue_per_store</th>\n      <th>total_revenue_per_day</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HOBBIES_1_002_CA_1_validation</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>d_800</td>\n      <td>0.0</td>\n      <td>2013-04-07</td>\n      <td>11311</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>3.97</td>\n      <td>train_val</td>\n      <td>2013</td>\n      <td>4</td>\n      <td>7</td>\n      <td>6</td>\n      <td>0</td>\n      <td>5.0</td>\n      <td>319.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>15528686.0</td>\n      <td>4469083.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HOBBIES_1_002_CA_1_validation</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>d_801</td>\n      <td>0.0</td>\n      <td>2013-04-08</td>\n      <td>11311</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3.97</td>\n      <td>train_val</td>\n      <td>2013</td>\n      <td>4</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>319.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>15528686.0</td>\n      <td>4445660.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HOBBIES_1_002_CA_1_validation</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>d_802</td>\n      <td>0.0</td>\n      <td>2013-04-09</td>\n      <td>11311</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.97</td>\n      <td>train_val</td>\n      <td>2013</td>\n      <td>4</td>\n      <td>9</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>319.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>15528686.0</td>\n      <td>4557555.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HOBBIES_1_002_CA_1_validation</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>d_803</td>\n      <td>0.0</td>\n      <td>2013-04-10</td>\n      <td>11311</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.97</td>\n      <td>train_val</td>\n      <td>2013</td>\n      <td>4</td>\n      <td>10</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>319.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>15528686.0</td>\n      <td>4301710.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HOBBIES_1_002_CA_1_validation</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>d_804</td>\n      <td>0.0</td>\n      <td>2013-04-11</td>\n      <td>11311</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.97</td>\n      <td>train_val</td>\n      <td>2013</td>\n      <td>4</td>\n      <td>11</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3.0</td>\n      <td>319.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>15528686.0</td>\n      <td>4401590.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_val_test.info()","execution_count":20,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 32376116 entries, 0 to 32376115\nData columns (total 30 columns):\nid                          category\nitem_id                     int16\ndept_id                     int8\ncat_id                      int8\nstore_id                    int8\nstate_id                    int8\nd                           category\nsales                       float32\ndate                        datetime64[ns]\nwm_yr_wk                    int16\nevent_name_1                int8\nevent_type_1                int8\nevent_name_2                int8\nevent_type_2                int8\nsnap_CA                     float32\nsnap_TX                     float32\nsnap_WI                     float32\nsell_price                  float32\npart                        category\nyear                        int16\nmonth                       int8\nday                         int8\nweekday                     int8\nhour                        int8\nitem_sales_per_day          float32\nitem_sales_per_store        float32\nitem_sales_per_store_day    float32\nrevenue                     float32\ntotal_revenue_per_store     float32\ntotal_revenue_per_day       float32\ndtypes: category(3), datetime64[ns](1), float32(11), int16(3), int8(12)\nmemory usage: 2.5 GB\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_col = ['item_id','dept_id','cat_id','store_id','state_id','event_name_1','event_type_1','event_name_2','event_type_2']\nnan_features = [\"event_name_1\", \"event_type_1\", \"event_name_2\", \"event_type_2\"]\n\ndf_train_val_test[nan_features] = df_train_val_test[nan_features].astype(object)\n\nfor col in cat_col:\n\n    if df_train_val_test[col].isnull().values.any():\n        df_train_val_test[col].fillna('unknown', inplace=True)\n\n    le = LabelEncoder()\n    df_train_val_test[col] = le.fit_transform(df_train_val_test[col])\n\ndf_train_val_test[cat_col] = df_train_val_test[cat_col].astype('category')","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_val_test.head()","execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"                              id item_id dept_id cat_id store_id state_id  \\\n0  HOBBIES_1_002_CA_1_validation       1       0      0        0        0   \n1  HOBBIES_1_002_CA_1_validation       1       0      0        0        0   \n2  HOBBIES_1_002_CA_1_validation       1       0      0        0        0   \n3  HOBBIES_1_002_CA_1_validation       1       0      0        0        0   \n4  HOBBIES_1_002_CA_1_validation       1       0      0        0        0   \n\n       d  sales       date  wm_yr_wk event_name_1 event_type_1 event_name_2  \\\n0  d_800    0.0 2013-04-07     11311            0            0            0   \n1  d_801    0.0 2013-04-08     11311            0            0            0   \n2  d_802    0.0 2013-04-09     11311            0            0            0   \n3  d_803    0.0 2013-04-10     11311            0            0            0   \n4  d_804    0.0 2013-04-11     11311            0            0            0   \n\n  event_type_2  snap_CA  snap_TX  snap_WI  sell_price       part  year  month  \\\n0            0      1.0      1.0      0.0        3.97  train_val  2013      4   \n1            0      1.0      0.0      1.0        3.97  train_val  2013      4   \n2            0      1.0      1.0      1.0        3.97  train_val  2013      4   \n3            0      1.0      0.0      0.0        3.97  train_val  2013      4   \n4            0      0.0      1.0      1.0        3.97  train_val  2013      4   \n\n   day  weekday  hour  item_sales_per_day  item_sales_per_store  \\\n0    7        6     0                 5.0                 319.0   \n1    8        0     0                 1.0                 319.0   \n2    9        1     0                 2.0                 319.0   \n3   10        2     0                 2.0                 319.0   \n4   11        3     0                 3.0                 319.0   \n\n   item_sales_per_store_day  revenue  total_revenue_per_store  \\\n0                       0.0      0.0               15528686.0   \n1                       0.0      0.0               15528686.0   \n2                       0.0      0.0               15528686.0   \n3                       0.0      0.0               15528686.0   \n4                       0.0      0.0               15528686.0   \n\n   total_revenue_per_day  \n0              4469083.5  \n1              4445660.0  \n2              4557555.0  \n3              4301710.5  \n4              4401590.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>item_id</th>\n      <th>dept_id</th>\n      <th>cat_id</th>\n      <th>store_id</th>\n      <th>state_id</th>\n      <th>d</th>\n      <th>sales</th>\n      <th>date</th>\n      <th>wm_yr_wk</th>\n      <th>event_name_1</th>\n      <th>event_type_1</th>\n      <th>event_name_2</th>\n      <th>event_type_2</th>\n      <th>snap_CA</th>\n      <th>snap_TX</th>\n      <th>snap_WI</th>\n      <th>sell_price</th>\n      <th>part</th>\n      <th>year</th>\n      <th>month</th>\n      <th>day</th>\n      <th>weekday</th>\n      <th>hour</th>\n      <th>item_sales_per_day</th>\n      <th>item_sales_per_store</th>\n      <th>item_sales_per_store_day</th>\n      <th>revenue</th>\n      <th>total_revenue_per_store</th>\n      <th>total_revenue_per_day</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HOBBIES_1_002_CA_1_validation</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>d_800</td>\n      <td>0.0</td>\n      <td>2013-04-07</td>\n      <td>11311</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>3.97</td>\n      <td>train_val</td>\n      <td>2013</td>\n      <td>4</td>\n      <td>7</td>\n      <td>6</td>\n      <td>0</td>\n      <td>5.0</td>\n      <td>319.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>15528686.0</td>\n      <td>4469083.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HOBBIES_1_002_CA_1_validation</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>d_801</td>\n      <td>0.0</td>\n      <td>2013-04-08</td>\n      <td>11311</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3.97</td>\n      <td>train_val</td>\n      <td>2013</td>\n      <td>4</td>\n      <td>8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>319.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>15528686.0</td>\n      <td>4445660.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>HOBBIES_1_002_CA_1_validation</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>d_802</td>\n      <td>0.0</td>\n      <td>2013-04-09</td>\n      <td>11311</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.97</td>\n      <td>train_val</td>\n      <td>2013</td>\n      <td>4</td>\n      <td>9</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>319.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>15528686.0</td>\n      <td>4557555.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>HOBBIES_1_002_CA_1_validation</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>d_803</td>\n      <td>0.0</td>\n      <td>2013-04-10</td>\n      <td>11311</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.97</td>\n      <td>train_val</td>\n      <td>2013</td>\n      <td>4</td>\n      <td>10</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2.0</td>\n      <td>319.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>15528686.0</td>\n      <td>4301710.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>HOBBIES_1_002_CA_1_validation</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>d_804</td>\n      <td>0.0</td>\n      <td>2013-04-11</td>\n      <td>11311</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.97</td>\n      <td>train_val</td>\n      <td>2013</td>\n      <td>4</td>\n      <td>11</td>\n      <td>3</td>\n      <td>0</td>\n      <td>3.0</td>\n      <td>319.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>15528686.0</td>\n      <td>4401590.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_val_test.info()","execution_count":23,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 32376116 entries, 0 to 32376115\nData columns (total 30 columns):\nid                          category\nitem_id                     category\ndept_id                     category\ncat_id                      category\nstore_id                    category\nstate_id                    category\nd                           category\nsales                       float32\ndate                        datetime64[ns]\nwm_yr_wk                    int16\nevent_name_1                category\nevent_type_1                category\nevent_name_2                category\nevent_type_2                category\nsnap_CA                     float32\nsnap_TX                     float32\nsnap_WI                     float32\nsell_price                  float32\npart                        category\nyear                        int16\nmonth                       int8\nday                         int8\nweekday                     int8\nhour                        int8\nitem_sales_per_day          float32\nitem_sales_per_store        float32\nitem_sales_per_store_day    float32\nrevenue                     float32\ntotal_revenue_per_store     float32\ntotal_revenue_per_day       float32\ndtypes: category(12), datetime64[ns](1), float32(11), int16(2), int8(4)\nmemory usage: 2.5 GB\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Feature-engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"# total items sold per day\nitem_sells_day = df_train_val_test.groupby(['item_id','date']).agg({'sales':'sum'})\nitem_sells_day.columns = ['item_sales_per_day']\nitem_sells_day.reset_index(inplace=True)\n\ndf_train_val_test = pd.merge(df_train_val_test, item_sells_day, on=['item_id','date'], how='left')\ndf_train_val_test['item_sales_per_day'] = df_train_val_test['item_sales_per_day'].astype(np.float32)\n\ndel item_sells_day\ngc.collect()","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"0"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# total items sold per store\nitem_sells_store = df_train_val_test.groupby(['item_id','store_id']).agg({'sales':'sum'})\nitem_sells_store.columns = ['item_sales_per_store']\nitem_sells_store.reset_index(inplace=True)\n\ndf_train_val_test = pd.merge(df_train_val_test, item_sells_store, on=['item_id','store_id'], how='left')\ndel item_sells_store\ndf_train_val_test['item_sales_per_store'] = df_train_val_test['item_sales_per_store'].astype(np.float32)\n\ngc.collect()","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"0"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# total items sold per store and day\nitem_sells_store_day = df_train_val_test.groupby(['item_id','store_id','date']).agg({'sales':'sum'})\nitem_sells_store_day.columns = ['item_sales_per_store_day']\nitem_sells_store_day.reset_index(inplace=True)\n\ndf_train_val_test = pd.merge(df_train_val_test, item_sells_store_day, on=['item_id','store_id','date'], how='left')\ndel item_sells_store_day\ndf_train_val_test['item_sales_per_store_day'] = df_train_val_test['item_sales_per_store_day'].astype(np.float32)\n\ngc.collect()","execution_count":14,"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"0"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_val_test['revenue'] = df_train_val_test['sell_price'] *  df_train_val_test['sales']","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# revenue per store\nrevenue_per_store = df_train_val_test.groupby('store_id').agg({'revenue':'sum'})\nrevenue_per_store.columns = ['total_revenue_per_store']\nrevenue_per_store.reset_index(inplace=True)\ndf_train_val_test = pd.merge(df_train_val_test, revenue_per_store, on=['store_id'], how='left')\ndel revenue_per_store\ndf_train_val_test['total_revenue_per_store'] = df_train_val_test['total_revenue_per_store'].astype(np.float32)\n\ngc.collect()","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"13"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# revenue per day\nrevenue_per_day = df_train_val_test.groupby('day').agg({'revenue':'sum'})\nrevenue_per_day.columns = ['total_revenue_per_day']\nrevenue_per_day.reset_index(inplace=True)\ndf_train_val_test = pd.merge(df_train_val_test, revenue_per_day, on=['day'], how='left')\ndel revenue_per_day\ndf_train_val_test['total_revenue_per_day'] = df_train_val_test['total_revenue_per_day'].astype(np.float32)\n\ngc.collect()","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"0"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n# revenue per store + day - crashes\nrevenue_per_store_day = df_train_val_test.groupby(['store_id','date']).agg({'revenue':'sum'})\nrevenue_per_store_day.columns = ['total_revenue_per_store_day']\nrevenue_per_store_day.reset_index(inplace=True)\n\ndf_train_val_test = pd.merge(df_train_val_test, revenue_per_store_day, on=['store_id'], how='left')\ndel revenue_per_store_day\ndf_train_val_test['total_revenue_per_store_day'] = df_train_val_test['total_revenue_per_store_day'].astype(np.float32)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_val_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%whos DataFrame","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train model"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n### split into training and validation set with 80% training and 20% validation\n# i.e. 80% of days into training and 20% of days into validation set\nndays_train_val = df_train_val_test[df_train_val_test.part=='train_val'].date.nunique()\ndays_train = round(ndays_train_val*0.8)\ndays_val = ndays_train_val-days_train\nprint('Using {} days for training and {} days for validation, {} days in total'.format(days_train,days_val,ndays_train_val))\nlast_day_train = str(df_train_val_test.date.unique()[days_train-1])\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nx_train = df_train_val_test[df_train_val_test['date'] <= last_day_train]\nx_val = df_train_val_test[(df_train_val_test['date'] > last_day_train) & (df_train_val_test['date'] < str(df_train_val_test[df_train_val_test.part=='public_leaderboard'].date[0]))]\ny_train = x_train['sales']\ny_val = x_val['sales']\nx_train.drop(['d', 'date', 'id', 'part', 'sales'], axis=1, inplace=True)\nx_val.drop(['d', 'date', 'id', 'part', 'sales'], axis=1, inplace=True)\ntest = df_train_val_test[df_train_val_test.part.str.contains(\"leaderboard\")]\nx_test = test.drop(['d', 'date', 'id', 'part', 'sales'], axis=1)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#x_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#x_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### lgb model\n'''\n\n#del df_train_val_test\ngc.collect()\n\n# define random hyperparammeters\nparams = {\n    'boosting_type': 'gbdt',\n    'metric': 'rmse',\n    'objective': 'regression',\n    'n_jobs': -1,\n    'seed': 236,\n    'learning_rate': 0.1,\n    'bagging_fraction': 0.75,\n    'bagging_freq': 10, \n    'colsample_bytree': 0.75}\n\ntrain_set = lgb.Dataset(x_train, y_train)\nval_set = lgb.Dataset(x_val, y_val)\n\n#del x_train, y_train\n\nmodel = lgb.train(params, train_set, num_boost_round = 2500, early_stopping_rounds = 50, valid_sets = [train_set, val_set], verbose_eval = 100)\nval_pred = model.predict(x_val)\nval_score = np.sqrt(metrics.mean_squared_error(val_pred, y_val))\nprint(f'Our val rmse score is {val_score}')\ny_test_pred = model.predict(x_test)\n\n# Plot feature importance\nlgb.plot_importance(model)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n### create submission file\ntest = df_train_val_test[df_train_val_test.part=='public_leaderboard']\ntest['sales'] = y_test_pred\npredictions = test[['id', 'date', 'demand']]\npredictions = pd.pivot(predictions, index = 'id', columns = 'date', values = 'demand').reset_index()\npredictions.columns = ['id'] + ['F' + str(i + 1) for i in range(28)]\n\nevaluation_rows = [row for row in submission['id'] if 'evaluation' in row] \nevaluation = submission[submission['id'].isin(evaluation_rows)]\n\nvalidation = submission[['id']].merge(predictions, on = 'id')\nfinal = pd.concat([validation, evaluation])\nfinal.to_csv('submission.csv', index = False)\n'''","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":4}